# Inspired by work of @Gary Stafford
version: "3.7"
services:
  pyspark:
    image: jupyter/all-spark-notebook:latest
    ports:
    - "18888:8888/tcp"
    - "14040:4040/tcp"
    networks:
    - pyspark-network
    working_dir: /home/$USER/work
    environment:
      CHOWN_HOME: "yes"
      GRANT_SUDO: "yes"
      NB_UID: 1000
      NB_GID: 100
      NB_USER: $USER
      NB_GROUP: staff
    user: root
    deploy:
     replicas: 1
     restart_policy:
       condition: on-failure
    volumes:
    - $PWD/work:/home/$USER/work
    - $PWD/scripts:/home/$USER/scripts
    logging:       
      driver: "json-file"
      options:     
        max-size: "50m"
        max-file: "10"
  postgres:
    env_file:
      - .env
    image: postgres:13.1-alpine
    environment:
      - "POSTGRES_USERNAME: babu"
      - "POSTGRES_PASSWORD: babupawd"
      - "POSTGRES_DB: babudb"
    ports:
    - "15432:5432/tcp"
    networks:
    - pyspark-network
    volumes:
    - $PWD/volumes/postgres:/var/lib/postgresql/data
    deploy:
      restart_policy:
       condition: on-failure
    logging:       
      driver: "json-file"
      options:     
        max-size: "50m"
        max-file: "10"    
  adminer:
    image: adminer:latest
    ports:
    - "18080:8080/tcp"
    networks:
    - pyspark-network
    deploy:
     restart_policy:
       condition: on-failure
    logging:       
      driver: "json-file"
      options:     
        max-size: "50m"
        max-file: "10"

networks:
  pyspark-network: